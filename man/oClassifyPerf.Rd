% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/oClassifyPerf.r
\name{oClassifyPerf}
\alias{oClassifyPerf}
\title{Function to evaluate the prediction performance via ROC and Precision-Recall (PR) analysis}
\usage{
oClassifyPerf(
prediction,
GSP,
GSN,
rescale = FALSE,
plot = c("none", "ROC", "PR"),
highlight = FALSE,
trim = TRUE,
verbose = TRUE
)
}
\arguments{
\item{prediction}{a data frame containing predictions along with
predictive scores. It has two columns: 1st column for subjects, 2nd
column for predictive scores on subjects}

\item{GSP}{a vector containing Gold Standard Positives (GSP)}

\item{GSN}{a vector containing Gold Standard Negatives (GSN)}

\item{rescale}{logical to indicate whether to linearly rescale
predictive scores for GSP/GSN to the range [0,1]. By default, it sets
to false}

\item{plot}{the way to plot performance curve. It can be 'none' for no
curve returned, 'ROC' for ROC curve, and 'PR' for PR curve.}

\item{highlight}{logical to indicate whether a dot is highlighted. It
only works when plot is drawn. When true, the maximum accuracy
highlighted in ROC curve, and the Fmax highlighted in PR curve. By
default, it sets to false}

\item{trim}{logical to indicate whether data points are evenly trimmed
to the maximum number of 1000}

\item{verbose}{logical to indicate whether the messages will be
displayed in the screen. By default, it sets to TRUE for display}
}
\value{
an object of class "pPerf", a list with following components:
\itemize{
\item{\code{data}: a data frame with 8 columns, including 4 performance
measures ('Accuracy', 'Precision', 'Recall' and 'Specificity'), 'name'
(subjects), 'pred' (predictive scores), 'label' (1 for GSP and 0 for
GSN), 'corrected' (corrected/transformed predictiv scores, always the
higher the better)}
\item{\code{auroc}: a scalar value for ROC AUC}
\item{\code{fmax}: a scalar value for maximum F-measure}
\item{\code{amax}: a scalar value for maximum accuracy}
\item{\code{direction}: '+' (the higher score the better prediction)
and '-' (the higher score the worse prediction)}
\item{\code{gp}: a ggplot object (if plotted) or NULL}
\item{\code{Pred_obj}: a ROCR prediction-class object (potentially used
for calculating other performance measures)}
}
}
\description{
\code{oClassifyPerf} is supposed to assess the prediction performance
via Receiver Operating Characteristic (ROC) and Precision-Recall (PR)
analysis. It requires three inputs: 1) Gold Standard Positive (GSP)
targets; 2) Gold Standard Negative (GSN) targets; 3) prediction
containing predictive scores on subjects. It returns an object of class
"pPerf".
}
\note{
AUC: the area under ROC
F-measure: the maximum of a harmonic mean between precision and recall
along PR curve
}
\examples{
\dontrun{
pPerf <- oClassifyPerf(prediction, GSP, GSN)
}
}
